# 통계학 7주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_7th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

7주차는 `3부. 데이터 분석하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_7th_TIL

### 3부. 데이터 분석하기
### 13.머신러닝 분석 방법론
### 14.모델 평가



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | ✅      | 
|7주차| 3부 p.357~615  | ✅      | 

<!-- 여기까진 그대로 둬 주세요-->

# 13.머신러닝 분석 방법론

```
✅ 학습 목표 :
* 선형 회귀와 다항 회귀를 비교하고, 데이터를 활용하여 적절한 회귀 모델을 구축할 수 있다. 
* 로지스틱 회귀 분석의 개념과 오즈(Odds)의 의미를 설명하고, 분류 문제에 적용할 수 있다.
* k-means 알고리즘의 원리를 설명하고, 적절한 군집 개수를 결정하여 데이터를 군집화할 수 있다.
```

## 13.1. 선형 회귀분석과 Elastic Net(예측모델)
> 평균으로의 회귀 이론의 경험적 연구로 회귀분석이 시작됨 -> 독립변수의 평균을 통해 종속변수 예측
✅ 회귀분석이란, 종속변수 Y의 값에 영향을 주는 독립변수 X들의 조건을 고려해서 구한 평균값
```
회귀선 -> 절편, 기울기, 오차항으로 구성
오차항=독립변수가 종속변수에 주는 영향력을 제외한 변화량을 뜻하므로 -> 회귀분석의 목적은 이 오차항을 최소화하는 절편과 기울기를 구하는 것
```
⚠️ 회귀분석은 독립변수 간 상관관계가 없어야 하기 때문에 다중공선성 검사가 필요함
1. 잔차의 정규성
    - 잔차의 히스토그램을 그리거나 Q-Q Plot을 통해 정규분포와 비교
    - Shapiro-Wilk test 또는 Anderson-Darling test 사용
2. 잔차의 등분산성
3. 독립성
4. 선형성


### 최소제곱추정법
예측치와 관측치들 간의 수직 거리의 제곱합을 최소로 하는 직선이 회귀선이 됨
=> 잔차제곱합(RSS)을 최소화하는 알파와 베타 값을 찾는 것

### 다중 회귀분석
![statweek_1](/git_stat/13.1.png)
- Standard Error는 표준오차를 의미하므로 값이 크면 예측값-실젯값의 차이가 큰 것
- 변수마다 스케일 단위가 다르므로 표준오차 절댓값만으로는 판단 어려움->T value 사용
- T value는 독립변수와 종속변수 간 선형관계가 얼마나 강한지를 나타냄->값이 커야 함
- P value는 유의도를 나타내고 T value오 관측치 수에 의해 결정됨
-> 이러한 통계량을 통해 모델에 최종적으로 사용할 변수를 선택할 수 있음
-> 변수 조합에 따라 통계량이 변함
-> 수동으로 찾는 것은 비효율적이므로 자동 선택하는 알고리즘 사용
```
1. 전진 선택법
- 절편만 있는 모델에서 시작하여 유의미한 독립변수 순으로 하나씩 추가
- 한번 선택된 변수는 다시 제거되지 않음!!

2. 후진 제거법
- 모든 독립변수가 포함된 상태에서 시작하여 유의미하지 않은 독립변수 순으로 하나씩 제거
- 마찬가지로 한번 제거된 변수는 다시 추가되지 않음
- 전진 선택법보다는 안전

3. 단계적 선택법
- 전진 선택법+후진 제거법
- 처음에는 변수를 하나씩 추가하고, 변수가 3개 이상이 되면 추가와 제거를 번갈아 수행
```
```python
# 데이터 시각화로 분포 확인해서 변수 간 상관관계 확인
sns.pairplot(df[["price", "sqft_living", "sqft_basement"]])

# OLS
ols_m = sm.OLS(y_train, sm.add_constant(x_train)).fit()
ols_m.summary()

# 다항회귀
from sklearn.preprocessing import PolyminalFeatures

poly_m = PolynomialFeatures(degreee=2, include_bias=False)
x_train_poly = poly_m.fit_transform(x_train)

mreg_poly = LinearRegression(fit_intrcept=True)

mreg_poly.fit(x_train_poly, y_train)

x_test_poly = poly_m.fit_transform(x_test)
y_predict_poly = mreg_poly.predict(x_test_poly)
```

## 13.2. 로지스틱 회귀분석 (분류모델)
> 선형회귀분석과 유사하지만 종속변수가 양적척도가 아닌 질적척도->어떤 카테고리에 들어갈지 분류

![statweek_2](/git_stat/13.2.png)
> 선형 회귀선은 이항의 종속변수를 직선으로 표현하므로 확률이 무한대가 됨->오즈 값으로 변환하여 로짓 회귀선으로 변환

![statweek_3](/git_stat/13.2.1.png)
- 선형 회귀분석과 대체로 유사하지만, 각 변수의 오즈비를 추가로 알 수 있음

## 13.8. k-means 클러스터링(군집모델)
> KNN은 지도 학습이고 k-means는 비지도학습->KNN은 분류고 k-means는 군집화

```
적절한 k의 수 정하기
1. 도메인 지식 활용
2. 엘보우 기법 -> 그래프에서 Inertia value가 급감하는 구간의 k를 선정
3. 실루엣 계수 -> -1~1의 범위에서 1에 가까울수록 적합하게 나누어진 것
```

### DBSCAN
> k를 별도로 지정하지 않고, 관측치들의 밀도를 통해 자동으로 군집의 수를 찾음

# 14. 모델 평가

```
✅ 학습 목표 :
* 유의확률(p-value)을 해석할 때 주의할 점을 설명할 수 있다.
* 분석가가 올바른 주관적 판단을 위한 필수 요소를 식별할 수 있다.
```

## 14.3. 회귀성능 평가지표
1. R^2(결정계수)
    - 모델의 독립변수들이 종속변변수를 설명할 수 있는 설명력을 나타냄
2. Adjusted R-Squre
    - R^2는 독립 변수의 개수가 많아질수록 값이 커짐(무의미한 변수를 추가해도 설명력이 커지게 되는 것)
    - SSE와 SST를 각각의 자유도로 나눔
3. RMSE(평균 제곱 오차)
    - 실제 수치와 예측 수치의 차이를 확인
    - 예측값 스케일에 영향을 받기 때문에 표본 데이터가 다르면 비교 불가
4. MAE(평균 절대 오차)
    - 실젯값과 예측값의 차이 절댓값 합을 n으로 나눈 값
    - 절대적인 전체 오차 크기를 더 중시할지, 모델의 예측 안정성을 중시할지에 따라 MAE와 RMSE 중 선택
5. MAPE
    - MAE를 퍼센트로 변환한 것
    - 스케일에 관계없이 절대적인 차이를 비교할 수 있음
    - 0에서 무한대의 값을 가지며, 0에 가까울수록 우수한 모델
6. RMSLE
    - 실젯값과 예측값에 1을 더해준 다음 로그를 취해 상대적 비율 비교
7. AIC
    - 독립변수의 개수에 페널티를 반영하여 계산
    - 작을수록 좋은 모델, 우도가 높을수록/변수가 적을수록 값이 작아짐
    - BIC는 변수 개수에 대한 페널티를 더 강하게 부여

## 14.6. 유의확률의 함정
> p값은 지반 간 차이가 없다라는 귀무가설을 검증하는 데 사용 -> p값이 작다는 것은 변수가 귀무가설을 지지하지 않음을 의미
> 하지만 p값은 표본의 크기가 커지면 표본 오착 작아지고 점점 0으로 수렴

![statweek_4](/git_stat/14.6.png)
> 연 소득 차이는 10만원으로 같지만, 표본이 증가하면서 p값이 확 낮아짐

## 14.7. 분석가의 주관적 판단과 스토리텔링
```
1. 20~30 여성을 타겟으로 한 차종인데 50~60 남성의 구매 예측 확률이 높음
-> 첫차 구입시기에 부모가 대신 구입해줌
-> 모델 예측 결과만 믿고 50~60 남성 대상 프로모션을 진행했다면 효과가 없었을 것!

2. 통신사에서 약정 기간이 끝난 고객들에게 맞춤형 프로모션 진행
-> 프로모션을 하지 않은 고객보다 프로모션을 한 고객들의 이탈률이 더 높았음
-> 약정이 끝났다는 프로모션을 보고 다른 통신사로 옮길 수 있다는 사실을 인지
-> 해지 방어를 위한 프로모션이 오히려 고객 이탈의 트리거가 된 것
-> 약정이 끝났을 때 이탈할 확률이 높은 고객 대상 프로모션 진행
```
✅ 데이터는 사람들의 문화나 심리를 반영하지 못하는 경우가 많음
✅ 해당 분야의 도메인 지식을 숙지할 것
✅ EDA와 전처리를 충실하게 수행할 것
✅ 데이터와 모델 검증을 거치며 인사이트를 얻을 것

### 스토리텔링 구조
배경-문제-극복-변화
1. 배경-문제
- 구체적 수치를 통해 집중시키기

2. 극복
- 분석과 개선 과정의 신뢰성 확보를 위해 데이터 수집/설명 필요
- 기본적 통계 수치와 그래프
- 개선방향이 타당한지가 가장 중요

3. 변화
- 개선된 내용을 수치로 표현

<br>
<br>

# 확인 문제

## **문제 1. 선형 회귀**

> **🧚 칼 피어슨의 아버지와 아들의 키 연구 결과를 바탕으로, 다음 선형 회귀식을 해석하세요.**  
> 칼 피어슨(Karl Pearson)은 아버지(X)와 아들(Y)의 키를 조사한 결과를 바탕으로 아래와 같은 선형 회귀식을 도출하였습니다. 아래의 선형 회귀식을 보고 기울기의 의미를 설명하세요. 
>  
> **ŷ = 33.73 + 0.516X**  
>   
> - **X**: 아버지의 키 (cm)  
> - **ŷ**: 아들의 예상 키 (cm)  

```
아버지의 키가 1cm 증가할 때 아들의 예상 키가 평균적으로 0.516cm 증가함을 의미한다.
```
---

## **문제 2. 로지스틱 회귀**  

> **🧚 다트비에서는 학생의 학업 성취도를 예측하기 위해 다항 로지스틱 회귀 분석을 수행하였습니다. 학업 성취도(Y)는 ‘낮음’, ‘보통’, ‘높음’ 3가지 범주로 구분되며, 독립 변수는 주당 공부 시간(Study Hours)과 출석률(Attendance Rate)입니다. 단, 기준범주는 '낮음' 입니다.**   

| 변수 | Odds Ratio Estimates | 95% Wald Confidence Limits |  
|------|----------------------|--------------------------|  
| Study Hours | **2.34** | (1.89, 2.88) |  
| Attendance Rate | **3.87** | (2.92, 5.13) |  

> 🔍 Q1. Odds Ratio Estimates(오즈비, OR)의 의미를 해석하세요.

<!--변수 Study Hours의 오즈비 값이 2.34라는 것과 Attendance Rate의 오즈비 값이 3.87이라는 것이 각각 무엇을 의미하는지 구체적으로 생각해보세요.-->


```
Study Hours의 오즈비 값 2.34는 Study Hours가 1단위 증가할 때 학업 성취도가 낮음에서 보통/높음으로 바뀔 확률이 2.34배 높아짐을 의미함.
Attendance Rate의 오즈비 값 3.87는 Attendance Rate가 1단위 증가할 때 학업 성취도가 낮음에서 보통/높음으로 바뀔 확률이 3.87배 높아짐을 의미함.
-> Attendance가 더 강한 영향력을 가짐
```

> 🔍 Q2. 95% Wald Confidence Limits의 의미를 설명하세요.
<!--각 변수의 신뢰구간에 제시된 수치가 의미하는 바를 생각해보세요.-->

```
각 변수의 실제 오즈비 값이 95% 확률로 이 신뢰구간 안에 존재한다는 것을 의미함.
```

> 🔍 Q3. 이 분석을 기반으로 학업 성취도를 향상시키기 위한 전략을 제안하세요.
<!--Study Hours와 Attendance Rate 중 어느 변수가 학업 성취도에 더 큰 영향을 미치는지를 고려하여, 학업 성취도를 향상시키기 위한 효과적인 전략을 구체적으로 제시해보세요.-->

```
Attendance Rate의 오즈비 값이 더 크므로, 학업 성취도에 더 큰 영향을 미친다. 따라서 출석률을 우선적으로 관리하는 것이 필요하다. 출석률이 높은 학생에게 가점을 부여하는 등의 전략이 효과적일 것이다.
```

---


## **문제 3. k-means 클러스터링**

> **🧚 선교는 고객을 유사한 그룹으로 분류하기 위해 k-means 클러스터링을 적용했습니다. 초기에는 3개의 군집으로 설정했지만, 결과가 만족스럽지 않았습니다. 선교가 최적의 군집 수를 찾기 위해 사용할 수 있는 방법을 한 가지 이상 제시하고 설명하세요.**

```
엘보우 기법
: 각 k값에 대해 WCSS 값을 계산하고 이를 그래프로 그려서 감소폭이 급격히 줄어드는 지점의 k값을 택함
```

### 🎉 수고하셨습니다.