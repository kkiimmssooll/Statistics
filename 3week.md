# 통계학 3주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_3rd_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

2주차는 `2부-데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_3rd_TIL

### 2부. 데이터 분석 준비하기
### 08. 분석 프로젝트 준비 및 기획
### 09. 분석 환경 세팅하기



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | 🍽️      | 
|5주차| 2부 p.203~254  | 🍽️      | 
|6주차| 3부 p.300~356  | 🍽️      | 
|7주차| 3부 p.357~615  | 🍽️      |  

<!-- 여기까진 그대로 둬 주세요-->

# 08. 분석 프로젝트 준비 및 기획

```
✅ 학습 목표 :
* 데이터 분석 프로세스를 설명할 수 있다.
* 비즈니스 문제를 정의할 때 주의할 점을 설명할 수 있다.
* 외부 데이터를 수집하는 방법에 대해 인식한다.
```

## 8.1 데이터 분석의 전체 프로세스
```
1. 설계단계
- 무엇을 하고자 하는지 명확하게 정의
2. 분석 및 모델링 단계
- 데이터 추출/검토/가공/모델링
- KDD 분석 방법론, CRISP-DM 방법론, SEMMA 방법론 등
3. 구축 및 활용 단계
- 분석 모델 적용 및 성과 측정
- A/B 테스트
```
### CRISP-DM 방법론
1. 비즈니스 이해
- 현재 상황 평가-데이터 마이닝 목표 결정-프로젝트 계획 수립
2. 데이터 이해
- 데이터 설명-데이터 탐색-데이터 품질 확인
3. 데이터 준비
- 데이터 선택-데이터 정제-필수 데이터 구성-데이터 통합
4. 모델링
- 모델링 기법 선정-테스트 디자인 생성-모델 생성-모델 평가
5. 평가
- 결과 평가-프로세스 검토-다음 단계 결정
6. 배포
- 배포 계획-모니터링 및 유지 관리 계획-최종 보고서 작성-프로젝트 검토

### SAS SEMMA 방법론
1. Sampling(데이터 추출)
- 전체 데이터에서 *분석용 데이터 추출*
- 의미 있는 정보를 추출하기 위한 *데이터 분할 및 병합*
- 표본추출을 통해 대표성을 가진 분석용 데이터 생성
- 분석 모델 생성을 위한 *학습, 검증, 테스트 데이터셋 분할*
2. Exploration(데이터 탐색)
- *통계치 확인, 그래프 생성* 등을 통해 데이터 탐색
- *상관분석, 클러스터링* 등을 통해 변수 간의 관계 파악
- 분석 모델에 적합한 *변수 선정*
- 데이터 현황을 파악하여 비즈니스 아이디어 도출 및 분석 방향 설정
3. Modification(변수 가공)
- *결측값 처리* 및 최종 변수 선정
- *로그변환, 구간화* 등 데이터 가공
- *주성분분석* 등을 통해 새로운 변수 생성
4. Modeling(모델 구축)
- 다양한 데이터마이닝 기법 적용에 대한 적합성 검토
- 비즈니스 목적에 맞는 분석 모델을 선정하여 분석 알고리즘 적용
- 지도학습, 비지도학습, 강화학습 등 데이터 형태에 따라 알맞은 모델 적용
- 분석 환경 인프라 성능과 모델 정확도를 고려한 모델 세부 옵션 설정
5. Assessment(모델 평가)
- 구축한 모델들의 예측력 등 성능을 비교, 분석, 평가
- 비즈니스 상황에 맞는 적정 임계치 설정
- 분석 모델 결과를 비즈니스 인사이트에 적용
- 상황에 따라 추가적인 데이터 분석 수행

```
정리하면!
비즈니스 문제/해결 방향 명확히 정의, 데이터 탐색->데이터 수집 및 가공, 머신러닝 모델 사용->데이터 분석 결과 검토 및 검증, 적용
```

## 8.2 비즈니스 문제 정의와 분석 문제 도출
- MECE 방식은 로직 트리를 활용하여 세부 항목을 정리

- 문제를 어떻게 정의하느냐에 따라 데이터 분석 및 모델링의 방햐이 달라질 수 있음, 본질적인 문제를 찾아야 함
    - 약정이 끝난 고객들이 타 통신사로 이탈->회사의 수익 감소

## 8.3 분석 목적의 전환
- 원활한 협력을 위해 단순한 것이라도 시각화를 활용해볼 수 있음

## 8.4 도메인 지식
- 유사한 주제의 논문에서 사용됐던 방법론 참고하기

## 8.5 외부 데이터 수집과 크롤링
- 분석 목적을 명확히 정의하고, 데이터를 수집
- 파이썬에서는 BeautifulSoup이나 Selenium을 활용하여 크롤링링

# 09. 분석 환경 세팅하기

```
✅ 학습 목표 :
* 데이터 분석의 전체적인 프로세스를 설명할 수 있다.
* 테이블 조인의 개념과 종류를 이해하고, 각 조인 방식의 차이를 구분하여 설명할 수 있다.
* ERD의 개념과 역할을 이해하고, 기본 구성 요소와 관계 유형을 설명할 수 있다.
```

## 9.1 어떤 데이터 분석 언어를 사용하는 것이 좋을까?
- **SAS**
    - 프로그래밍 언어보다는 솔루션에 가까움
    - 데이터 시각화를 쉽게 할 수 있음
- **R**
    - 통계적 기능이 우수하며 데이터 시각화에 특화
    - ggplot2, ggvis, googleVis 등의 시각화 패키지
- **파이썬**
    - sklearn, tensorflow 등의 기계학습 도구
    - pandas, numpy, matplotlib 등의 데이터 분석용 도구
- **SQL**
    - 관계형 데이터베이스 시스템에서 데이터를 관리 및 처리

## 9.2 데이터 처리 프로세스 이해하기
```
OLTP : 실시간으로 데이터를 트랜잭션 단위로 수집/분류/저장장 
-> DW(ODS) : 여러 시스템에 산재되어 있던 데이터들을 한 곳으로 취합하여 모아놓는 저장소
-> DM : 사용자의 목적에 맞도록 가공된 일부 데이터가 저장(부서나 사용자 집단의 필요에 맞게 가공된 개별 데이터 저장소)
-> OLAP
```

## 9.3 분산데이터 처리
- HDFS : 데이터 분산 시스템
    - 슬레이브 노드 : 데이터를 저장하고 계산
    - 마스터 노드 : 대량의 데이터를 HDFS에 저장하고 맵리듀스 방식을 통해 데이터를 병렬 처리
    - 클라이언트 머신 : 맵리듀스 작업을 통해 산출된 결과를 사용자에게 보여줌
- 맵리듀스 : HDFS에 저장된 데이터를 효과적으로 처리
    - 맵 : 흩어져 있는 데이터를 관련된 데이터끼리 묶어서 임시의 집합을 만드는 과정
    - 리듀스 : 정렬, 병합 등의 과정으로 나눠져 있던 결과를 취합
- 하둡
    - 1.0 : JobTracker(리소스 관리 시스템)
    - 2.0 : JobTracker를 Resource Manager/Application Master/Timeline Server 등으로 분리하여 기능 고도화

- 스파크 : 분산 데이터 처리 시스템
    - 인메모리 기반의 빠른 데이터 처리
- 제플린 : 시각화 툴

## 9.4 테이블 조인과 정의서 그리고 ERD
### 테이블 조인
1. 레프트&라이트 조인
- 하나의 테이블을 기준으로 다른 테이블에서 겹치는 부분을 결합
- 기준 테이블 데이터는 유지하면서 조인 테이블의 데이터만 추가
2. 이너 조인
- 두 테이블 간의 겹치는 부분의 행만 가져옴
3. 풀 조인
- 모든 행을 가져옴
4. 크로스 조인

### 데이터 단어사전
- 메타데이터 관리 시스템 : 데이터가 어디에 어떻게 저장되어 있는지, 어떻게 사용할 것인지를 이해할 수 있도록 데이터에 대한 정보를 관리하는 시스템
    - 메타데이터 : 각 테이블과 거기에 포함된 데이터의 속성에 관한 정보, 데이터 간의 관계를 정의한 데이터에 대한 정보를 관리하는 시스템

### 테이블 정의서
- DB에 대한 파악이 된 후에 보는 것이 유용

### ERD
- Primary Key : 테이블에 적재된 각각의 데이터를 유일하게 구분 -> 결측값을 가질 수 없음
- Foreign Key : 각 테이블 간에 연결을 만들기 위해 테이블에서 다르 테이블에 참조되는 기본 키 -> 중복이나 결측값이 있을 수 있음
- ERD 연결 관계

 



<br>
<br>

# 확인 문제

## 문제 1.

> **🧚 아래의 테이블을 조인한 결과를 출력하였습니다. 어떤 조인 방식을 사용했는지 맞춰보세요.**

> 사용한 테이블은 다음과 같습니다.

![TABLE1](https://github.com/ejejbb/Template/raw/main/File/2.6.PNG)|![TABLE2](https://github.com/ejejbb/Template/raw/main/File/2.7.PNG)
---|---|

> 보기: INNER, LEFT, RIGHT 조인

<!-- 테이블 조인의 종류를 이해하였는지 확인하기 위한 문제입니다. 각 테이블이 어떤 조인 방식을 이용하였을지 고민해보고 각 테이블 아래에 답을 작성해주세요.-->

### 1-1. 
![TABLE](https://github.com/ejejbb/Template/raw/main/File/2-1.PNG)
```
LEFT JOIN
```

### 1-2. 
![TABLE](https://github.com/ejejbb/Template/raw/main/File/2-3.PNG)
```
INNER JOIN
```

### 1-3. 
![TABLE](https://github.com/ejejbb/Template/raw/main/File/2-2.PNG)
```
RIGHT JOIN
```

### 🎉 수고하셨습니다.